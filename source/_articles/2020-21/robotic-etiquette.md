---
layout: post
issue: "2020"
category: feature
order: 5
title: Robotic etiquette
subhead: "Engineering improved human-robot interaction"
author:
  name: Ramin Skibba
  file: "2020/ramin-skibba.jpg"
  url: 
banner:
  file: 
  position: left
further-inquiry:
    - title: "Takayama L, Dooley D, Ju W. Expressing thought: improving robot readability with animation principles. Proceedings of the 6th ACM/IEEE International Conference on Human-Robot Interaction. March 2011, 69-76."
      url: https://doi.org/10.1145/1957656.1957674
    - title: "Srinivasan V, Takayama L. Help Me Please: Robot Politeness Strategies for Soliciting Help From Humans. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. May 2016 4945-4955."
      url: https://dl.acm.org/doi/10.1145/2858036.2858217
    - title: "Walker N, Weatherwax K, Allchin J, Takayama L, Cakmak M. Human Perceptions of a Curious Robot that Performs Off-Task Actions.Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (HRI). March 2020, 529-538."
      url: https://doi.org/10.1145/3319502.3374821
   
in-the-news:
    - title: "Love 'em or hate 'em, robots are here to stay so let's make them better, says psychology prof. (UCSC News, September 12, 2017)"
      url: https://news.ucsc.edu/2017/09/takayama-robots.html
    - title: "Stop me if you've heard this one: a robot and a team of Irish scientists walk into a senior living home. (<em>Time</em>, October 4, 2019,)"
      url: https://time.com/longform/senior-care-robot/
    - title: "Would you let a robot take care of your mother? (<em>New York Times</em>, December 13, 2019)"
      url: https://www.nytimes.com/2019/12/13/opinion/robot-caregiver-aging.html
    - title: Tug, the busy little robot nurse, will see you now. (<em>Wired</em>, November 10, 2017).
      url: https://www.wired.com/story/tug-the-busy-little-robot-nurse-will-see-you-now/
---

<figure class="left" style="width:300px;">
  {% asset 2020/leila-takayama.jpg @magick:resize=300 alt:'Associate professor of computational media Leila Takayama' %}<figcaption>Associate professor of computational media Leila Takayama works in the
growing field of human-robot interaction, which seeks to improve this
interaction by studying robots, like the one sitting here in Takayama's
hand, and their human users to better understand the dynamics on both
sides of the relationship. Credit: Melissa De Witte.</figcaption>
</figure>

Most people don't know what to do when they first encounter a robot.
Some swarm around it. Some stand back. And some misinterpret its
behavior. That's what happened to [**Leila
Takayama**](https://www.soe.ucsc.edu/people/takayama), UC
Santa Cruz associate professor of computational media, when she first
met PR2 (Personal Robot 2), a [social
robot](https://en.wikipedia.org/wiki/Social_robot) built by
the robotics company [Willow
Garage](https://en.wikipedia.org/wiki/Willow_Garage).

When she walked through the front door of the company's Palo Alto
headquarters, the PR2 rolled up to her and paused. She expected a
greeting, but it spun its head around and ran away. "I felt blown off,
but that doesn't make sense," Takayama said. "It was just trying to get
from point A to point B and was replanning its path, but I couldn't help
but feel insulted."

It's natural to misread a robot's intentions, both because of how robots
are currently designed and also our usually inflated expectations of
what they can do, said Takayama, who aims to improve both sides of this
stilted relationship with her research on [human-robot
interaction](https://en.wikipedia.org/wiki/Human%E2%80%93robot_interaction).
This growing field of study, driven by rapid advances in both artificial
intelligence and robotics engineering, employs a broad set of
disciplines to explore a wide range of challenging subjects, from how
humans work with remote, tele-operated unmanned vehicles and surgical
robots, to self-driving vehicles and collaborations
with anthropomorphic social robots.

While personal computers have become much more user-friendly over time,
that's not the case for robots. "They're still in the dark ages, in
terms of being usable and useful for normal people. I felt like that's a
pretty big problem that could be addressed with better human-centered
design and research," Takayama said.

## Bad manners ##

In the next several decades, we'll likely see a wide range of robots
ambling about our hospitals, homes, workplaces, and groceries, as well
as on sidewalks and in the street, where autonomous cars count as
robots, too. Prototypes of those future robots already wander about some
cities, especially in the Bay Area. But today's robots lack the subtle
common sense we humans take for granted every day as we navigate our
social world. And without this common sense in robots, humans get
confused. Takayama's broad background in the social sciences, cognitive
science, behavioral science, and psychology, comes in handy here, giving
her insights that engineers might not recognize as relevant and
important.

For example, in order to conserve power, engineers typically build
robots to be efficient with their motions. But that can be a problem,
said [Wendy
Ju](https://tech.cornell.edu/people/wendy-ju/), an
assistant professor of information science at Cornell University and
frequent Takayama collaborator. "The unintended effect is that robots
seem stiff, even kind of snotty. Robots need to move around to seem
natural and make people feel more comfortable. That's something that
only someone who studies people would think of," she said.
<figure class="" style="width:600px;">
  {% asset 2020/robot.jpg @magick:resize=600 alt:'PR2 Robot' %}<figcaption>Humans commonly misread a robot&#39;s intentions, as was the case when
Takayama first encountered a PR2 robot, like the one shown here, and it
surprised her by appearing to run away. No longer in business, Willow
Garage, the robot&#39;s Palo Alto--based maker, spent years investing in
robotics research that produced the PR2&#39;s sophisticated visual and
tactile sensors and open-source software. Credit: <a href="https://commons.wikimedia.org/wiki/File:PR2_robot_with_advanced_grasping_hands.JPG">Oleg
Alexandrov</a>
(CC BY-SA 3.0).</figcaption>
</figure>

To improve robot manners, Takayama and her team are working to help them
take cues from people. When a robot trundles into an elevator, it
typically does the selfish thing and sits smack in the center, leaving
little room for human passengers. The same happens in hospital
corridors, where robots bother staff by hogging space. "Most humans know
it's not polite to do that. We use interactive behavior programming to
help people help robots do the right thing&mdash;it's basically teaching
them social skills," Takayama said.

As might be expected, people warm up to robots that behave more like
people. In one collaboration, Takayama is studying people's perceptions
of robots that spend time exploring, in addition to performing a primary
task. The findings of this work, [presented in March
2020](https://doi.org/10.1145/3319502.3374821) at a human-robot
interaction conference, showed that people often have positive views of
these "curious" robots, but assessed competence drops when these robots
deviate too far from their task.

In an earlier
[project](http://www.leilatakayama.org/downloads/Takayama.Animation_HRI2011_prepress.pdf),
Takayama tapped an expert animator to help generate movements for a
robot that allowed people to understand its intentions, to open a door
or pick up a bottle, for instance. "Takayama showed how a robot can be
incredibly expressive," said [Anca
Dragan](https://people.eecs.berkeley.edu/~anca/), an
assistant professor of electrical engineering and computer sciences at
UC Berkeley. Dragan was developing algorithms that enable robots to work
with, around, and in support of people, and Takayama's demonstration
inspired her to work on robots to autonomously have expressive motions:
"I ended up asking is there a way for the robot to come up with those
motions itself?"

Ultimately, if robots behave more expressively, people can better
understand what they're doing and anticipate what they're going to do.
This has important consequences for self-driving cars, Dragan said,
since the way robots drive needs to be consistent with human driving,
and both need to anticipate the other to avoid accidents.

## Human side ##

Importantly, when humans and robots both learn, both benefit.
Human-robot interactions improve when people have more informed and
realistic expectations of a robot's abilities, said [Laurel
Riek](https://cseweb.ucsd.edu/~lriek/), an associate
professor of computer science and emergency medicine at UC San Diego.

In a [recent
study](http://cseweb.ucsd.edu/~lriek/papers/washburn-adeleye-an-riek-THRI-2020.pdf),
which supports the findings in Takayama's work, Riek asked people to
collaborate with a mobile robot to cooperatively hang a large banner.
Unbeknownst to participants, the robot was intentionally programmed to
make mistakes, such as dropping its end. Some participants were told the
robot might malfunction, and they responded differently from others who
received no warning. "The participants in the low-expectation setting
recovered more quickly from the errors, regaining trust in the robot and
improving their perceptions of its reliability," Riek said.

The implication is that people's unrealistic expectations can hamper
their interactions with robots. The videos they see online, such as the
popular YouTube clips of the [robots built by Boston
Dynamics](https://www.youtube.com/watch?v=YdnJI9T-yXI),
give the wrong impression, Takayama said. "I wish they'd show more of
the blooper reels, the 199 takes before the demo finally worked. This
stuff is hard. Robots are actually not that capable," she said.

These outsized expectations also have important implications for the
robot-enabled future, beyond their immediate impact on human-robot
interactions. People have preconceived notions about robots shaped by
decades of media-fueled hope, fear, and hype. Early roboticists
envisioned anthropomorphic robots with broad, human-like functionality,
a concept now firmly planted in the minds of most people. It's now
clear, however, that robots work best when they're specialized, which
translates to myriad different designs depending on the robot's main
task. The faceless robot that stocks the shelves will be strikingly
different from the one with the friendly face working the cash register.
<figure class="" style="width:600px;">
  {% asset 2020/robot-collage.png @magick:resize=600 alt:'PR2 Robot' %}<figcaption>False impressions and unrealistic expectations stemming from media and
popular culture portrayals have promoted hope, hype, and fear about
robots and artificial intelligence, said Takayama. Robots in science
fiction, like in (top row, L to R) the <em>Doctor Who</em> TV series and the
<em>Star Wars</em> and <em>Terminator</em> movies, are far more capable than currently
available robot technology. Most of today&#39;s robots, like (bottom row, L
to R) the Roomba vacuum cleaner, the da Vinci surgical robot, and the
Robomower, are made to excel only at a single task. Credits: <a href="https://commons.wikimedia.org/wiki/File:Doctor_Who_50th_Celebration_-_Cyberman_(11001236893"><em>Doctor
Who</em></a>,
<a href="https://commons.wikimedia.org/wiki/File:Terminator.JPG"><em>Terminator</em></a>,
<a href="https://commons.wikimedia.org/wiki/File:IRobot_Roomba_870_(15860914940">Roomba</a>
(CC BY 2.0); <a href="http://pngimg.com/download/28371"><em>Star Wars</em></a> (CC BY-NC
4.0); <a href="https://commons.wikimedia.org/wiki/File:WBAMC_first_in_DoD_to_use_robot_for_surgery_160426-A-EK666-506.jpg">da
Vinci</a>
(public domain);
<a href="https://commons.wikimedia.org/wiki/File:Robomow_110_City_2012-06-05.jpg">Robomower</a>
(CC BY-SA 3.0).</figcaption>
</figure>
The image problem is exacerbated by the media portrayals of humanoid
robots that frequently give the impression of much broader capability
than is actually the case, Takayama said. Such robots typically
disappoint when encountered in real life, offering just a highly
articulated face and not much else. These false impressions contribute
to the hype that surrounds and damages the field, Takayama said. "If
you're going to make it look like a human, you should make it live up to
those expectations," she said. "Why not make a Roomba instead?"

Portrayals of robots in popular culture have also contributed to the
misconceptions. East Asian science fiction, like the Japanese series
[*Astro Boy*](https://en.wikipedia.org/wiki/Astro_Boy),
has promoted both hope and fear about artificial intelligence and
robots. More recent Western movies like [*Robot &
Frank*](https://en.wikipedia.org/wiki/Robot_%26_Frank) and
series like [*Westworld*](https://www.hbo.com/westworld)
ask nuanced questions about potential relationships with robots, but
robot portrayals in earlier ones, like Hal in [*2001: A Space
Odyssey*](https://en.wikipedia.org/wiki/2001:_A_Space_Odyssey_(film)),
primarily warned about the potential dangers of a robotic future,
Takayama said.

Takayama and her colleagues are hard at work trying to shape a robotic
future that reflects the best of humanity. "We should be thinking harder
about what robots we *should* be building, not just what robots we
*could* be building," she said. "Just because you can build it, is that
the future we want? That's the real question."
